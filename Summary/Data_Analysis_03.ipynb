{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Data_Analysis_03.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIM6l5Z1bTvx",
        "colab_type": "text"
      },
      "source": [
        "## 신경망 모델 ( Neural networks )\n",
        "    - 머신러닝 기법 중 하나로 널리 쓰이고 있는 방법\n",
        "\n",
        "   * 물체를 보는 자극이 뉴런을 타고 전달되고, 시냅스로 뇌신경까지 신호 전달. \n",
        "     - 뉴런 네트워크 // Feed-forward network \n",
        "     - 입력데이터 ($x$)  ***  타켓($y$)\n",
        "\n",
        "   - 신호가 전달되는 과정에서 가중치 할당! \n",
        "   - Input node 의 수는 내가 가지고 있는 데이터 입력 변수의 수\n",
        "   - Output node 는 target variables 에 따라 달라짐. \n",
        "   - 활성함수\n",
        "\n",
        "----\n",
        "\n",
        "## 인공 신경망의 학습\n",
        "\n",
        " - 추론은 정방향으로, 학습은 역방향으로 \n",
        " - 역전파 방법으로 학습이 일어남 \n",
        "\n",
        " ** 노드와 연결되어 있는 가중치를 학습 // 입력 데이터를 넣어 타겟 값을 계산(추론)\n",
        "\n",
        "----\n",
        "## 딥러닝(Deep Learning)\n",
        "\n",
        " - 인공 신경망이 더 발전된 형태\n",
        " - 데이터 표현을 직접 학습하여 높은 수준의 추상화를 시도, 머신러닝 알고리즘의 집합\n",
        "\n",
        "•\t데이터를 학습한 후 각각의 인덱싱으로 정보를 매칭 시키는 형태 \n",
        "\n",
        "((((  딥러닝 < 학습 모델링 < 머신러닝 < 인공지능 ))))\n",
        "\n",
        " - 딥러닝 == convolution neural networks  // recurrent neural networks 등 \n",
        "\n",
        "----\n",
        "### 파라미터 vs 하이퍼 파라미터 \n",
        "\n",
        " - 파라미터 : 모델의 구성요소이자 데이터로부터 학습되는 것 \n",
        " \n",
        "  ex) 선형 회귀 모델 == 직선의 방정식 : Y = aX + b (a,b 가 파라미터)\n",
        "         - 신경망 == 가중치들 \n",
        "\n",
        "    - 하이퍼 파라미터 :  학습 이전에 미리 값을 결정하는 과정\n",
        "\n",
        "  ex) 3개의 오븐에 다른 세팅으로 빵을 구우면? \n",
        "\n",
        " - 데이터 : 반죽 // 오븐의 셋팅 값 : 하이퍼 파라미터 // 결과 : 모델 \n",
        "    •\t좋은 모델을 만들기 위해서는 하이퍼 파라미터의 튜닝/컨트롤이 중요\n",
        "\n",
        "  ex) 신경망 : 네트워크의 구조 \n",
        "\t\n",
        "    - 은닉 노드 수 증가 / 은닉 층 추가\n",
        "\n",
        "----\n",
        "## 손실함수 ( Loss Function ) \n",
        "\n",
        "       학습 알고리즘이 작동하게끔 만드는 원동력 \n",
        "        \n",
        "       - 손실함수의 값을 줄여나가는 과정이 곧 모델을 학습하는 과정\n",
        "\n",
        "\n",
        "    실제 데이터에서 관측된 결과 vs 모델에 의해 생성된 결과 \n",
        "      - 둘의 차이에 의해 ‘손실’ 발생!!!!! \n",
        "      - 손실이 작아야 모델 성능이 좋음 \n",
        "\n",
        "\n",
        "\n",
        "\n",
        " - 활성함수를 거쳐 나온 결과 == 파이($\\pi$)\n",
        "\n",
        "\n",
        " - 손실함수의 종류 : 교차 엔트로피,  평균 제곱 오차 \n",
        "\n",
        " * 2차 함수 : y=a(x-p)2 + q\n",
        "    \n",
        "    •\t최솟값 q == 꼭지점!! \n",
        "\n",
        " * 손실함수값(L) = 2(w-3)2+1\n",
        "    \n",
        "    •\t손실함수 값 L이 가장 작을 때, 파라미터 w 의 값은? w = 3\n",
        "\n",
        "---\n",
        "\n",
        "## 학습, 검증/ 개발, 테스트 셋 \n",
        "\n",
        "    ### 학습 셋 (training set)\n",
        "    -\t모델 생성을 위해 학습 과정에 사용\n",
        "    -\t모델 파라미터 추정을 위해 소모됨 \n",
        "\n",
        "    ### 검증/개발 셋(validation / development set)\n",
        "    -\t학습과정에서 하이퍼 파라미터를 튜닝하는데 사용 (셋팅값)\n",
        "    -\t하이퍼 파라미터를 쓰는게 적합한지 평가하는데 소모됨\n",
        "\n",
        "    ### 테스트 셋(test set)\n",
        "    -\t생성된 모델의 예측생성(predictive performance) 평가\n",
        "    -\t실제로는 타겟값이 있지만, 타겟값이 없다고 가정하고 예측이 잘 되는지 평가하는데 소모됨. \n",
        "\n",
        "----\n",
        "## [3-way holdout] 방법\n",
        "\n",
        "    1.\t가지고 있는 데이터를 3개로 분할 \n",
        "         학습, 개발, 테스트 셋\n",
        "    2.\thyper parameter 후보 모델로 학습 \n",
        "    3.\tvalidation set 을 이용하여 모델 평가\n",
        "         best model  / best hyperparameter 를 찾을 수 있음. \n",
        "    4.\tTraining set 과 validation set  을 합쳐서 도출된 \n",
        "        best hyperparameter 모델 재학습\n",
        "    5.\tTest set 으로 모델 평가 \n",
        "    6.\t모든 데이터로 최종 모델 학습  미래 예측에 사용\n",
        "\n",
        "\n",
        "    •\t고려할 사항\n",
        "    - training 70% / test 30% \n",
        "    \n",
        "    - 데이터 포인트 수가 충분한가?\n",
        "    \n",
        "    - Train/validation/test 의 데이터 분포가 동일한가?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxipht9AbTvz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}