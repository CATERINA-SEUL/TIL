{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Data_Analysis_05.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaKBeki2KMxF",
        "colab_type": "text"
      },
      "source": [
        "#### 크롤링 (Crawling)\n",
        "\n",
        "-\t다양한 정보를 활용하기 쉽도록 수집하는 행위가 크롤링\n",
        "-\t크롤링을 하는 프로그램을 크롤러(Crawler)라고 함\n",
        "-\t웹의 데이터를 자동화해 가져오는 크롤러가 웹 크롤러 \n",
        "-\t통상적으로 스크래핑(Scraping)이라는 말을 더 많이 사용\n",
        "\n",
        "#### HTML\n",
        "-\t하이퍼텍스트 마크업언어\n",
        "-\tWeb 페이지의 내용, 구조 등을 정의한 언어(F12)\n",
        "---\n",
        "\n",
        "#### ETL\n",
        "-\tExtract, Transformation, Loading의 줄임말\n",
        "-\t내외부의 다수의 데이터를 추출하고 이를 필요에 맞게 변환 후 저장하는 전처리 과정을 의미\n",
        "\n",
        "#### ELT\n",
        "-\tExtract, Loading, Transformation의 줄임말 \n",
        "-\tETL에서 transformation과 loading 의 순서를 바꿔서 진행\n",
        "\n",
        "#### ETL 오픈소스 도구 \n",
        " talend , pentaho, Apache NIFI(매우 안정적), KNIME, StreamSets 등\n",
        "\n",
        "---\n",
        "\n",
        "#### 정형데이터\n",
        "-\tStructured Data\n",
        "-\t엑셀 등의 스프레드시트에서 작업하 듯 열과 행을 정리하여 일목요연하게 표로 만들 수 있는 데이터\n",
        "-\t정형데이터를 쉽게 다루기 위해 관계형데이터베이스가 활용되기도 함\n",
        "-\t정형데이터를 file로 변환할 경우) csv, tsv로 저장\n",
        "\n",
        "#### 비정형데이터 \n",
        "-\tUnstructured Data\n",
        "-\t문서, 동영상, 사진, 음성 등의 형태를 정의할 수 없는 데이터\n",
        "-\t정형 데이터를 다루는 RDB에서는 활용 불가\n",
        "-\t분석을 위해서는 비정형 데이터를 정형화하는 다양한 과정이 필요함.\n",
        "\n",
        "#### 반정형데이터\n",
        "-\tSemi-structured Data\n",
        "-\t관계형 데이터베이스나 다른 형태의 데이터 테이블과 연결된 정형 구조의 데이터 모델을 준수하지 않는 정형데이터의 한 형태\n",
        "-\t각 의미를 구분할 수는 있지만 열과 행 형태의 표로 정리하기가 쉽지 않음 \n",
        "     *  parsing 필요\n",
        "-\tJson, XML, HTML\n",
        "---\n",
        "\n",
        "#### Data Warehouse\n",
        "-\t사용자의 의사 결정에 도움을 주기 위하여 여러 시스템의 데이터베이스에 축적된 데이터를 공통의 형식으로 변환해서 관리하는 데이터베이스를 말한\n",
        "-\t짧게 줄여 DW라고 함\n",
        "-\tDW 구축이란? \n",
        "    1)\t다양한 분석을 할 수 있도록 여러 테이블을 가공해 Mart Table 생성 \n",
        "        (지속적 업데이트가 필요)\n",
        "    2)\t이후 사용자는 분석 툴(e.g , OLAP, SQL)을 활용해 보다 편리하게 분석할 수 있도록 함\n",
        "\n",
        "#### Data Lake\n",
        "-\tdata warehouse 의 정보 분석 한계를 개선하기 위해 생긴 저장 개념\n",
        "-\tdata warehouse 는 정형데이터를 가공하여 저장, data lake 는 원래 형식으로 대량 저장하여 분석에 활용\n",
        "-\t정형, 비정형, 반정형 모두 가능\n",
        "-\tdata warehouse에 비해 더 큰 빅데이터 저장 공간 필요\n",
        "\n",
        "#### 데이터 적재 유형 \n",
        "-\tBounded data\n",
        "    1)\t일단 저장되면 변화가 없음\n",
        "    2)\t월 단위 매출 데이터, 신규 고객 유치 수 등 \n",
        "    3)\t처리는 묶어서 한 번에 처리\n",
        "\n",
        "-\tUnbounded data\n",
        "    1)\t끝을 지정할 수 없이 지속적으로 업데이트되는 데이터\n",
        "    2)\t시스템 로그데이터, 주식 가격 변동 데이터 등\n",
        "    3)\t끝이 정해지지 않기 때문에 주기적 처리 또는 실시간 처리 필요\n",
        " \n",
        "---\n",
        "#### 배치처리(Batch Processing)\n",
        "-\t일괄처리\n",
        "-\t대량의 데이터를 특정 시간에 한 번에 처리\n",
        "\n",
        "#### 스트림 처리(Stream Processing)\n",
        "-\t물의 흐름처럼 지속적으로 유입되는 데이터의 연속성 있는 처리\n",
        "-\tMicro Batch \n",
        "== 배치의 주기나 데이터 크기를 상대적으로 짧게 잡아 준 실시간으로 처리하는 것을 의미\n",
        "\n",
        "---\n",
        "#### 워크플로우(workflow) \n",
        "-\t작업 절차를 통한 정보 또는 업무의 이동을 의미 : 작업 흐름\n",
        "-\t데이터 워크 플로우는 데이터 처리의 작업 절차를 의미\n",
        "-\tETL 작업같은 데이터 처리 흐름을 워크플로우 스케줄링 툴로 처리\n",
        "\n",
        "#### DAG\n",
        "-\t방향성 비순환 그래프 (Directed Acyclic Graph)\n",
        "\n",
        "##### Apache Oozie \n",
        " * \tApache Airflow\n",
        "    1)\t에어비앤비 엔지니어링팀에서 개발한 도구\n",
        "    2)\tpython 기반으로 워크플로우 설계 가능\n",
        "    3)\t여러 머신에서 분산하여 수행\n",
        "    4)\tUI 기반의 모니터링 도구 제공\n",
        "\n",
        "---\n",
        "#### Computer Cluster\n",
        "-\t여러대의 컴퓨터들이 연결되어 하나의 시스템처럼 동작하는 컴퓨터들의 집합\n",
        "-\t물리적으로는 여러 대의 컴퓨터이지만 외부 사용자는 마치 한 대의 컴퓨터인 것으로 보임\n",
        "-\t구성요소\n",
        "1)\tNode (master + slave)\n",
        "2)\tNetwork \n",
        "3)\tOS\n",
        "4)\tMiddleware\n",
        "\n",
        "#### Cluster의 목적\n",
        "-\t서버의 확장을 통한 우수한 성능을 얻을 수 있음\n",
        "-\t분산 컴퓨팅 기술 요소가 필요\n",
        "\n",
        "#### SPOF (Single point of failure)\n",
        "-\t단일 장애지점\n",
        "-\t시스템 구성 중에 동작하지 않는 것이 있으면 전체가 중단\n",
        "-\t일종의 치명적인 약점으로 클러스터에서 SPOF가 존재하면 안됨 !!!\n",
        "\n",
        "#### HA(high availability)\n",
        "-\t고가용성\n",
        "-\t서버와 네트워크, 프로그램 등의 시스템이 지속적으로 운영이 가능한 성질\n",
        "-\t클러스터에서는 SPOF가 없어야 하며, HA 가 유지되어야 함\n",
        "\n",
        "---\n",
        "#### Scale UP\n",
        "-\t서버 자체 RAM, CPU, DISK 등의 구성요소 자체를 업그레이드 하여 성능을 향상 시키는 방법\n",
        "-\t무한 확장 불가능\n",
        "-\t성능 증가에 따라 가격이 급등\n",
        "-\t확장에 따른 공간 확보가 필요 없음\n",
        "-\t과부하가 걸릴 때 한 서버에 집중될 수 있음 // 단일서버\n",
        "#### Scale Out\n",
        "-\t네트워크 상의 서버 수를 늘려 컴퓨팅 성능을 향상 시키는 방법\n",
        "-\t각 서버를 Cluster로 묶기 때문에 사용자는 1대를 활용하는 것처럼 느낌\n",
        "-\t이론상으로는 무한 확장 가능\n",
        "-\t저렴한 서버를 여러대 사용하여 비용 부담이 덜한 편\n",
        "-\t서버가 많아지기 때문에 공간 확보 필요\n",
        "-\t네트워크 비용이 증가\n",
        "-\t장애 발생시 어느 서버에서 발생했는지 확인이 필요\n",
        "-\tMaster + Slave\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpMe9V5JKMxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}